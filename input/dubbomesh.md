#  Dubbo Mesh的总结与展望
2018是阿里巴巴集团正式扬帆探索Service Mesh的元年。同年4月份正式组建了团队投入这一领域，经过半年多的努力，在年底终于在阿里巴巴集团内部完成了首个业务在生产环境的落地。

## 起航
众所周知，阿里巴巴在分布式应用领域的规模是空前的。在以Java为主要开发语言的背景下，经过十多年的发展，集团内部几乎构建了应对大规模分布式应用挑战的各种工具和系统。也正因如此，当面对Service Mesh这一新技术时，并不容易说清道白其价值，毕竟其所具备的功能在阿里巴巴集团都有相应的工具或系统。基于此，开始探索的第一步是想清楚Service Mesh对于阿里巴巴集团的价值，以价值去驱动技术发展是阿里巴巴集团所一贯主张的技术发展思路。

面对一项新技术，我们不只是看它带来了什么新内容，还要看解决了当下的什么挑战。简单说来，Service Mesh是一种基于“服务”这一核心概念的“层次化、规范化、体系化、无侵入的分布式应用治理”的技术方案。当然，这“三化一入”与阿里巴巴集团已有的那些工具和系统相比多少显得有些空洞。为此，需要我们转换一下视角，从当下阿里巴巴集团所面临的挑战去发掘Service Mesh所带来的价值。简单说来，我们看到了这些价值：
- **协调异构、不同技术栈的融合发展。** 在阿里巴巴集团不断通过收购子公司去扩大商业版图的背景下，这一价值应当足够的大，能很好地规避短期“铲掉重建”的风险。此外，在未来的分布式应用是天然多语言的趋势下，Service Mesh完全迎合了这一趋势，除了带来不同语言之间互联互通的便利性，还极大地降低了传统多语言SDK思路所遭受的巨大开发与维护成本。
- **解耦平台与业务技术栈的绑定，让各自聚焦独立演进。** “分而治之”是解决规模问题的有效范式，Service Mesh的核心思想依然包含了这一内容。通过解耦，业务技术团队无需关注平台技术的演进，甚至对平台技术的演进无感，将平台技术当作是业务应用的基础设施。平台技术全面负责服务发现与路由、灰度、限流、熔断、降级等所有分布式应用的（粗粒度）通用功能。
- **实现流量收口并统一治理。** 流量收口意味着整个分布式应用生态将采用统一的口径处理包含日志、指标、追踪在内的三大遥测数据，利于用一套运维系统进行体系化、全局最优的监管控。流量收口对于未来的Serverless解决方案具有非常重要的作用，让auto-scaling做到更智能、更敏捷。

在思考Service Mesh价值的同时，我们也着手技术方案的选型与设计。

## 选型
开源软件的蓬勃发展让任何人做技术选型时都不能忽视其存在。为此，我们定下了“借力开源，反哺开源”的选型与发展策略。“借力”的内涵是规避低层次的重复发明轮子，学习前人“走弯路”所沉淀的经验与智慧，将精力投入到高层次的创新与优化；“反哺”隐含的是将我们的成果普惠他人，这是“共赢”思想的必然行为，也是让厂商打消lock in担忧的明智之举。

在实施技术选型时，我们特别关注如下因素：
- **开源生态繁荣。** 在这点上，我们会重点关注开源软件在GitHub上的star、contributor数，commit频次和版本发布周期。相信这些指标能很好地表征开源生态的繁荣程度。
- **开源软件是否已商业化。** 重点关注该开源软件是否在大规模生产环境上经受了检验。
- **数据平面所采纳编程语言的大众化与运行时的确定性。** 编程语言如果过于小众，则很难招募到现有人才，势必会因为人才培养的周期拉长而影响了对Service Mesh的探索速度。数据平面因为承载了所有的服务调用流量而对性能特别敏感，编程语言的确定性能很好地帮助规避因为运行时GC（Garbage Collection)而导致的毛刺所带来的业务抖动问题。确定性也意味着运用技术所带来的机器成本能得到更为有效的控制。

综合以上因素，我们最终做了如下的技术选型：
- **数据平面选型Envoy。** Envoy由Lyft公司创建并运用于生产环境多年，在开源之后也有其他的公司基于Envoy打造商业产品，而Google也采纳了Envoy作为其公司内部Service Mesh的数据平面。Envoy是[CNCF](https://www.cncf.io/) Landscape的成员之一且目前成为了CNCF的毕业项目。在撰写本文之时，Envoy在GitHub的star数是8200+，contributor的人数超过270，大约2~3个月发布一个新版本。包含Google、IBM在内的诸多公司目前仍积极参与对之进行优化与完善。Envoy的编程语言是C++，能用更为精细和严苛的方式管理和使用系统资源去发挥计算资源的极致性能，这对于公司来说意味着更低的成本。Envoy所定义的、被广泛接受的xDS协议很好地体现了我们对Service Mesh具有“规范化”作用的理解。
- **控制平面选型Istio的Pilot组件。** 以Istio目前的架构设计和结合阿里巴巴集团已有软件资产的现状，其整体并不足以承载起对Service Mesh的要求。然而，其中的Pilot组件的平台抽象设计、对Envoy xDS协议的实现能很好地加速Service Mesh在阿里巴巴集团生产环境的落地。Pilot的编程语言是Go，在控制平面完全不走服务流量的前提下，Go这一云原生编程语言有着很好的开发效率，也比那些带有VM（Virtual Machine）的编程语言有着更小的内存开销。

## 探索
毫无疑问，借力开源能从整体上加速Service Mesh在阿里巴巴集团生产环境的落地，但与那种“从无到有自己造”的路径相比，前期的学习曲线更为陡峭、进度也更慢。原因在于，需要花时间去掌握他人的设计思路，只有尽可能延着已有的主导软件设计去扩展和优化才有可能做到“反哺开源”，否则只能“自得其乐”。

在探索的前期，我们曾采纳过Dubbo over HTTP/1.1的方式去落地。即，Dubbo的provider端提供HTTP调用RPC的能力，在consumer端则直接通过Envoy已成型的HTTP转发能力去调用provider，我们需要做的只是增加相应的路由能力。这个技术方案的最终性能测试表明，consumer和provider两端及Envoy所导致的性能开销都大到业务方无法接受，因为那意味着全面应用这一技术后需要更高的机器成本。即便将HTTP/1.1更换成HTTP/2而带来巨大的性能改善的情况下，这一结论依然没有改变。此外，虽说变更provider端增加HTTP调用的能力只是更新软件版本和重启应用那么简单，但这一动作并不利于前期的小范围推广，我们希望在Dubbo Mesh只支持outbound流量的情形下，能让provider端完全无感的方式在小范围先落地使用。

在得出Dubbo over HTTP无法快速落地的结论后，我们转为让Envoy原生支持Dubbo协议这一native的方式。在经历过性能测试和多路复用TCP连接池的功能优化后，其性能表现完全符合业务方的预期，也使得Dubbo Mesh最终在生产环境中承载了业务流量。

目前Envoy的GitHub仓库中已包含部分实现Dubbo协议的代码，还没有进到仓库的代码仍处于review状态。

## 数据
“运用Dubbo Mesh后，对于业务RT和单机CPU的影响究竟有多大”是我们在阿里巴巴集团内与业务方交流时经常被问及的问题。为此，我们在4核8G的[Pouch](https://github.com/alibaba/pouch)容器中制造了场景对Dubbo Mesh进行性能测试。具体的性能测试方案及业务落地案例我们将通过其他文章与大家分享。在此公布并发度为100时，Dubbo Mesh对业务RT和CPU负载的影响，如下表所示。

| **Envoy QPS** | **RT增幅（ms)** | **CPU增幅** |
| --- | --- | --- |
| 840 | 0.07 | 0.47 |
| 1680 | 0.08 | 0.81 |
| 2520 | 0.12 | 1.21 |
| 3360 | 0.14 | 1.54 |
| 4200 | 0.18 | 1.85 |
| 5040 | 0.22 | 1.83 |
| 5880 | 0.30 | 2.12 |
| 6720 | 0.37 | 1.86 |
| 7560 | 0.44 | 2.01 |
| 8400 | 0.55 | 1.96 |
| 9240 | 0.78 | 1.65 |
| 10080 | 1.19 | 1.89 |

表中的数据是代表一跳Envoy所带来的RT和CPU损耗。其中的“RT增幅”部分相信无需多讲，每多增加一跳将给业务服务调用的RT增加表中相应的时延。“CPU增幅”需要稍做解释，他是基于整个测试机的CPU为400%（即4核）而得出的。就这两个指标具体地说，假设业务服务调用在QPS为8400的情形下：在没有运用Dubbo Mesh时，RT是20ms，CPU负荷是130%；在使用Dubbo Mesh的情形下，RT将变成20.55ms、CPU则增加至131.96%。

表中数据显示，在QPS增大致1万时，所增加的RT超过了1ms，这是因为整个测试机器的负荷处于很高水位所致。评估Dubbo Mesh对于业务的影响需要特别注意这一点。总的说来，只要业务的机器资源在正常运行时不会进入高水位，则Dubbo Mesh对业务的影响很小。

## 洞见
Dubbo Mesh经过一年不到的探索期，我们收获了如下的洞见：
- **服务发现的时效性是Service Mesh技术的关键。** 以集群方式提供服务的情形下（这是分布式应用的常态），因为应用发布而导致集群中机器状态的变更如何及时准确地推送到数据平面是极具挑战的问题。对于阿里巴巴集团来说，这是属于[Nacos](https://github.com/alibaba/nacos)需关注的问题域。开源版本的Istio能否在生产环境中运用于大规模分布式应用也取决于这一能力。频繁的集群信息推送，将给控制平面和数据平面都带去负荷扰动，如何通过技术手段控制好扰动是需要特别关注的，对于数据平面来说编程语言的“确定性”在其中将起到关键作用。
- **数据平面的软件实现最大程度地减少内存分配与释放将显著地改善性能。** 有两大举措可以考虑：
    - **逻辑与数据相分离。** 以Dubbo Mesh在Envoy中实现Dubbo协议为例，Envoy每收到一个RPC请求都会动态地创建fitler去处理，一旦实现逻辑与数据相分离，filter的创建对于每一个worker线程有且只有一次，由于是无状态的而可以方便地处理后续收到的RPC请求。
    - **使用内存池。** Envoy的实现中基本上没有用到内存池，如果采用内存池对分配出来的各种bufffer通过链表进行缓存，这将省去大量的内存分配与释放而改善性能。
- **数据平面的runtime profiling是关键技术。** Service Mesh虽然对业务代码没有侵入性，但对服务流量具有侵入性，如何在出现业务毛刺的情形下，快速地通过智能runtime profiling去发现问题或自证清白是非常值得关注的点。

## 展望
在接下来的2019年，Dubbo Mesh将具备对inbound流量的管理而形成包含outbound和inbound“两条腿”的真正mesh。Mesh网络一旦成型，将进一步组合阿里巴巴集团已开源出来的各种组件去增强其监管控能力。比如，通过将[Sentinel](https://github.com/alibaba/Sentinel)的能力纳入到Dubbo Mesh，能很好地补全限流、降级和熔断的能力。

另外，迎合Serverless的技术发展趋势，如何通过Dubbo Mesh更好地轻量化应用，以及基于Dubbo Mesh对服务流量的天然敏感度而更好地实现auto-scaling也是值得重点探索的内容。

## 参考
* 李云在2018 QCon上海站分享的文字稿：《[Service Mesh的本质、价值和应用探索](https://mp.weixin.qq.com/s/Q6kEgxdpcGdEEmQ44cFpQQ)》
